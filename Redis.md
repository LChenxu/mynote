







# Redis基础架构

## 二.Redis高性能IO模型

### Redis基本IO模型

<img src="C:\Users\lcx76\Pictures\Saved Pictures\e18499ab244e4428a0e60b4da6575bc9.jpg" style="zoom: 25%;" />

### 阻塞点

- accept：Redis监听到一个客户端的连接请求，但是连接一直未成功时线程会在accept方法阻塞
- recv：Redis通过recv方法从客户端读取数据时，如果数据一直没有到达也会在此方法阻塞

### 基于linux IO多路复用机制

​		内核 同时存在多个**监听套接字**和**已连接套接字**，当客户端通过套接字发出请求时，内核监听并触发相应的事件，内核将事件写入**Redis的事件队列**中，Redis单线程会一直处理事件队列中的事件，而事件会**回调**Redis提供的相应的函数（*详细需要学习linux的IO多路复用模型*）

<img src="C:\Users\lcx76\Pictures\Saved Pictures\00ff790d4f6225aaeeebba34a71d8bea.jpg" style="zoom:25%;" />

### 问题

- 在“Redis 基本 IO 模型”图中，你觉得还有哪些潜在的性能瓶颈吗？

  Redis单线程处理IO请求性能瓶颈主要包括2个方面：

  1、任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：
  a、操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；
  b、使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；
  c、大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；
  d、淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；
  e、AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；
  f、主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；
  2、并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。

  针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。

  针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。

## 三.Redis宕机数据恢复问题

Redis从后端数据库存储到内存中，读取数据都在内存中非常快，但是内存中的数据宕机会丢失，有两种方式可以解决此问题：

- **从后端数据库恢复**：恢复大量数据会频繁访问后端数据库会给后端数据库带来压力，同时从磁盘读取大量数据性能肯定很差
- **数据持久化**：AOF日志和RDB快

### AOF日志

#### AOF日志是如何实现的？

和传统数据库的写前日志不同，AOF日志采用的是**写后日志**



*为什么？*

首先，**AOF日志保存的不是数据，而是Redis收到的一条条命令**，为了避免开销写AOF时不会对命令做语法语义检查，只有命令能执行成功后，AOF才能保证写入的日志是对的，恢复 数据时才不会有报错问题

其次，写后日志可以**避免阻塞当前写操作**，AOF日志也是Redis主线程执行的，线程写磁盘是性能很差的



<img src="C:\Users\lcx76\Pictures\Saved Pictures\4d120bee623642e75fdf1c0700623a9f.jpg" style="zoom:25%;" />

`*如上图，AOF记录的是命令，其中，“3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3 set”表示这部分有 3 个字节，也就是“set”命令。*`

同时，AOF写后日志方式也会存在两个风险：

- 命令执行完成，还没来得及写AOF日志就宕机了
- 避免阻塞当前的命令带来另一个问题：可能阻塞下一个命令

其实这两个风险都是日志写回磁盘的时机不当造成的

#### 三种写回策略

为了给AOF提供一个合适的写回时机，Redis提供了三种写回策略，对应AOF配置项的appendfsync的三个可选项

- **Always**，同步写回：每个写命令执行完，立刻将日志写回磁盘
- **Everysec**，每秒写回：每个写命令执行完，先将日志写到AOF文件的内存缓冲区，每隔一秒将缓冲区中的日志写回磁盘
- **No**，操作系统控制写回：每个写命令执行完，先将日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘

但是这三种写回策略并不能完美解决日志丢失和性能问题，以下是三种策略的优缺点

<img src="C:\Users\lcx76\Pictures\Saved Pictures\72f547f18dbac788c7d11yy167d7ebf8.jpg" style="zoom:25%;" />

#### 日志文件太大怎么办？

日志文件过大带了的问题：

- 文件系统可能不支持那么大的文件
- 往大文件中追加内容会造成效率问题
- 宕机后恢复会很慢，造成Redis的性能变差



***AOF的重写机制***

原理：Redis创建一个新的AOF文件，将当前Redis数据库的每个键值对用一条命令记录它的写入

<img src="C:\Users\lcx76\Pictures\Saved Pictures\6528c699fdcf40b404af57040bb8d208.jpg" style="zoom:25%;" />

重写过程：主线程 fork 出后台的 bgrewriteaof 子进程进行重写，不会阻塞主线程

- 一个拷贝：fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程（使用写时复制），这里面就包含了数据库的最新数据
- 两处日志：重写是一个费时的操作，如果此时有写命令，Redis会将命令分别写到旧日志和重写日志的日志缓冲区

<img src="C:\Users\lcx76\Pictures\Saved Pictures\6b054eb1aed0734bd81ddab9a31d0be8.jpg" style="zoom:25%;" />

`总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。`

#### 问题

- AOF 日志重写的时候，是由 bgrewriteaof 子进程来完成的，不用主线程参与，我们今天说的非阻塞也是指子进程的执行不阻塞主线程。但是，你觉得，这个重写过程有没有其他潜在的阻塞风险呢？如果有的话，会在哪里阻塞？
- AOF 重写也有一个重写日志，为什么它不共享使用 AOF 本身的日志呢？

问题1，Redis采用fork子进程重写AOF文件时，潜在的阻塞风险包括：fork子进程 和 AOF重写过程中父进程产生写入的场景，下面依次介绍。

a、fork子进程，fork这个瞬间一定是会阻塞主线程的（注意，fork时并不会一次性拷贝所有内存数据给子进程，老师文章写的是拷贝所有内存数据给子进程，我个人认为是有歧义的），fork采用操作系统提供的写时复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），**这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久**。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实时复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。

b、fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以**在Redis机器上需要关闭Huge Page机制**。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。

问题2，AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可。

### RDB快照

#### 给哪些内存数据做快照

Redis采用的是全量快照，也就是将某一时刻内存中的所有数据写入文件，有两个命令：

- save：主线程执行，会阻塞
- bgsave：创建一个子线程，不会阻塞Redis主线程

#### 快照时数据能修改吗？

bgsave快照生成会使用操作系统写时复制（copy on write）在主线程写数据前拷贝一个副本给bgsave子线程让其进行快照，这样快照的同时Redis主线程还可以对数据进行写操作，如下图	

<img src="C:\Users\lcx76\Pictures\Saved Pictures\4dc5fb99a1c94f70957cce1ffef419cc.jpg" style="zoom:25%;" />

#### 多久做一次快照

为了保证数据不丢失，间隔很短的时间做一次快照即可达到，但是间隔太短带来两个问题：

- 频繁将全量数据写入磁盘，会造成磁盘的压力，多个快照竞争磁盘带宽容易造成恶性循环
- bgsave子线程需要fork操作，这个操作会是主线程拷贝内存页表到子线程，会阻塞主线程，内存越大阻塞时间越长



**增量快照**，第一次快照之后，只快照被修改的键值对，但是会增加额外的内存空间消耗。



**Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法**

简单说就是内存快照按一定频率进行，两次快照之间用AOF做写操作命令日志

这样，快照不会很频繁，避免了fork线程对主线程的阻塞和消耗，而且AOF记录的内容变少，减少了日志重写的可能

#### 问题

2核CPU、4GB内存、500G磁盘，Redis实例占用2GB，写读比例为8:2，此时做RDB持久化，产生的风险主要在于 CPU资源 和 内存资源 这2方面：

a、内存资源风险：Redis fork子进程做RDB持久化，由于写的比例为80%，那么在持久化过程中，“写实复制”会重新分配整个实例80%的内存副本，大约需要重新分配1.6GB内存空间，这样整个系统的内存使用接近饱和，如果此时父进程又有大量新key写入，很快机器内存就会被吃光，如果机器开启了Swap机制，那么Redis会有一部分数据被换到磁盘上，当Redis访问这部分在磁盘上的数据时，性能会急剧下降，已经达不到高性能的标准（可以理解为武功被废）。如果机器没有开启Swap，会直接触发OOM，父子进程会面临被系统kill掉的风险。

b、CPU资源风险：虽然子进程在做RDB持久化，但生成RDB快照过程会消耗大量的CPU资源，虽然Redis处理处理请求是单线程的，但Redis Server还有其他线程在后台工作，例如AOF每秒刷盘、异步关闭文件描述符这些操作。由于机器只有2核CPU，这也就意味着父进程占用了超过一半的CPU资源，此时子进程做RDB持久化，可能会产生CPU竞争，导致的结果就是父进程处理请求延迟增大，子进程生成RDB快照的时间也会变长，整个Redis Server性能下降。

c、另外，可以再延伸一下，老师的问题没有提到Redis进程是否绑定了CPU，如果绑定了CPU，那么子进程会继承父进程的CPU亲和性属性，子进程必然会与父进程争夺同一个CPU资源，整个Redis Server的性能必然会受到影响！所以如果Redis需要开启定时RDB和AOF重写，进程一定不要绑定CPU。

## 四.主从库数据一致性研究

Redis主从库采用读写方式，主库从库都可以读，但是只有主库可以写

这样可以减少多个实例同时写的一致性难度和减少加锁的开销

### 主从库第一次同步

```
replicaof  172.16.19.3  6379 // 申请成为某一个实例从库命令
```

主从库第一次同步流程：

<img src="C:\Users\lcx76\Pictures\image\Redis第一次主从同步图" alt="img" style="zoom: 33%;" />

- 第一阶段：

  1. 从库发送 psync ？-1命令到主库：？代表主库的runID，此时还不知道主库的RunID是多少所以是？，-1表示此时从库的slave_repl_offset，和repl_backlog_buffer有关系，断网重连时会用到；
  2. 主库接到psync命令发送FULLRESYNC{runID}{master_repl_offset}到从库，FULLRESYNC代表全量复制，master_repl_offset将作为从库的初始偏移量。

- 第二阶段：

  主库创建子线程将所有数据生成RDB快照，发送给从库，从库清清除当前数据库并加载RDB文件

- 第三阶段：

  主库生成RDB快照和传输阶段不会停止工作，同时主库执行写命令并将其写到replication buffer中，并在发送玩RDB后发送到从库，完成第一次数据一致

## 五.哨兵机制

从库故障，Redis不受影响可以继续工作，等从库故障解除和主库做数据一致即可

**主库故障应该如何解决？**-->重新选出一个主库

选主的问题：

- 主库真的挂了吗
- 应该选哪个库做新主库
- 新主库的信息怎么传递给其他从库

### 哨兵机制的基本流程

- 监控：哨兵是一个特殊的Redis进程，它会周期性发PING到主从库。如果从库没有在规定时间响应PING命令，则哨兵进程标记从库为“下线状态”；如果主库没有在规定时间响应PING，哨兵会发起选主。
- 选主：从Redis集群其他库中选一个从库实例作为主库实例。
- 通知：选出新主库，哨兵将新主库的链接信息发送给其他从库让其执行 replicaof命令进行数据复制；并发送新出库连接信息到客户端，让客服端发写命令到新主库

![img](C:\Users\lcx76\Pictures\image\efcfa517d0f09d057be7da32a84cf2a1.jpg)

在这三个任务中，通知任务相对来说比较简单，哨兵只需要把新主库信息发给从库和客户端，让它们和新主库建立连接就行，并不涉及决策的逻辑。但是，在监控和选主这两个任务中，哨兵需要做出两个决策：

- 在监控任务中，哨兵需要判断主库是否处于下线状态；
- 在选主任务中，哨兵也要决定选择哪个从库实例作为主库。

### 监控：主观下线和客观下线

**主观下线**

一个哨兵PING一个Redis实例，没有在规定时间内得到响应，哨兵标记此实例下线，这就是**主观下线**。

但是判断主库下线失误的话，会进行主从切换，开销很大，所有有了

**客观下线**

哨兵集群实现，下章详解

![img](C:\Users\lcx76\Pictures\image\1945703abf16ee14e2f7559873e4e60d.jpg)

“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。

### 选主

选主过程=筛选+打分

#### **筛选**

1. **断线的筛掉**
2. **网络状态不好的筛掉**，通过down-after-milliseconds * 10判断网络状态，需要看看Redis设计与实现研究一下这个配置

#### **打分**

分3轮，只要在某一轮中，有从库得分最高，那么它就是主库了，3轮规则如下：

**从库优先级**

slave-priority配置可以给从库定优先级

比如可以将内存比较大的从库设置优先级比较高

**从库复制进度**

最接近旧主库复制进度的从库打分高

从库salve_repl_offset最接近旧主库master_repl_offset的获得最高分，成为主库

**从库ID号**

每个实例都会有一个 ID，这个 ID 就类似于这里的从库的编号。目前，Redis 在选主库时，有一个默认的规定：**在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高**，会被选为新主库。

### 问题

#### 哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？

如果客户端使用了读写分离，则读请求正常，主从切换过程中写请求会失败

**失败持续时间=哨兵切换主从时间+客户端感知到新主库时间**



如何让写请求不失败？

可以让客户端的写请求先写到缓存或消息队列中，但是也有两个问题：

- 这种方式只能应对 对写请求的返回值不敏感的业务
- 如果主从切换时间过长，那么缓存和消息队列中的写请求会很多，同时新主库选出后重放这么多写请求也会使用很长时间



**down-after-milliseconds对主从切换的影响**

哨兵监控实例，规定down-after-milliseconds时间内得不到回应即认为这个实例已经下线

- 配置的时间越短，哨兵越敏感，可以有效减少写失败持续时间，但是可能因为网络阻塞等造成不必要的主从切换
- 配置的时间越长，哨兵越保守，可以减少误判率，但是可能造成写失败持续时间长，缓存写请求太多



**主从切换后，客户端如何得到哨兵通知（即得到最新的主库地址）**

- 哨兵实例将新主库地址写在自己的pubsub中，客户端需要订阅这个pubsub
- 客户端主动获取主从地址方式：sentinel get-master-addr-by-name命令；当**实例异常时，哨兵切换后或者客户端断开重连**，都可以从哨兵集群中拿到最新的实例地址

## 六.哨兵集群

```
sentinel monitor <master-name> <ip> <redis-port> <quorum> 
```

上面的命令是哨兵配置信息，可见单个哨兵只是与主库有联系，那么哨兵之间如何互相发现，哨兵如何发现从库的呢？

### pub/sub机制

#### 哨兵互相发现

<img src="C:\Users\lcx76\Pictures\image\ca42698128aa4c8a374efbc575ea22b1.jpg" alt="img" style="zoom:25%;" />

哨兵通过发布订阅机制实现互相发现：通过向主库订阅相同的频道，然后发布自己的IP端口，其他哨兵订阅这个消息，互相间就可以知道对方的IP和端口了

#### 哨兵发现从库

<img src="C:\Users\lcx76\Pictures\image\88fdc68eb94c44efbdf7357260091de0.jpg" alt="img" style="zoom:25%;" />

哨兵向主库发送INFO命令，主库会返回从库列表

#### 客户端订阅哨兵事件

哨兵实例是一个特殊的Redis实例，所以哨兵也有pub/sub事件，客户端可以从哨兵订阅消息

<img src="C:\Users\lcx76\Pictures\image\4e9665694a9565abbce1a63cf111f725.jpg" alt="img" style="zoom: 25%;" />

客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行订阅命令，来获取不同的事件消息。

### 哨兵集群判断“客观下线”及选leader的过程

#### is-master-down-by-addr 命令

当一个哨兵判断主库“主观下线”后，会给其他哨兵发送is-master-down-by-addr 命令，来收取赞成票，自己占一票

<img src="C:\Users\lcx76\Pictures\image\e0832d432c14c98066a94e0ef86af384.jpg" alt="img" style="zoom:25%;" />

#### quorum 配置

当哨兵获取的赞成票大于等于配置的quorum时，就可以标记主库“客观下线”了，此后可以竞选leader进行主从切换

#### 成为Leader切换主从的条件

- 获取半数以上的赞成票（N/2+1）
- 赞成票大于等于quorum

如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1 票。

### 问题

**Redis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换？**

*经过实际测试，我的结论如下：*

1、哨兵集群可以判定主库“主观下线”。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，哨兵集群可以判定主库为“客观下线”。

2、但哨兵不能完成主从切换。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到多数选票的结果。

*但是投票选举过程的细节并不是大家认为的：每个哨兵各自1票，这个情况是不一定的。下面具体说一下：*

**场景a**：哨兵A先判定主库“主观下线”，然后马上询问哨兵B（注意，此时哨兵B只是被动接受询问，并没有去询问哨兵A，也就是它还没有进入判定“客观下线”的流程），哨兵B回复主库已“主观下线”，达到quorum=2后哨兵A此时可以判定主库“客观下线”。此时，哨兵A马上可以向其他哨兵发起成为“哨兵领导者”的投票，哨兵B收到投票请求后，由于自己还没有询问哨兵A进入判定“客观下线”的流程，所以哨兵B是可以给哨兵A投票确认的，这样哨兵A就已经拿到2票了。等稍后哨兵B也判定“主观下线”后想成为领导者时，因为它已经给别人投过票了，所以这一轮自己就不能再成为领导者了。

**场景b**：哨兵A和哨兵B同时判定主库“主观下线”，然后同时询问对方后都得到可以“客观下线”的结论，此时它们各自给自己投上1票后，然后向其他哨兵发起投票请求，但是因为各自都给自己投过票了，因此各自都拒绝了对方的投票请求，这样2个哨兵各自持有1票。

***场景a是1个哨兵拿到2票，场景b是2个哨兵各自有1票，这2种情况都不满足大多数选票(3票)的结果，因此无法完成主从切换。***

***经过测试发现，场景b发生的概率非常小，只有2个哨兵同时进入判定“主观下线”的流程时才可以发生。我测试几次后发现，都是复现的场景a。***

# 实践经验

## 一.string遇到的问题

**场景**

一个图片存储系统，要求这个系统能快速地记录图片 ID 和图片在存储系统中保存时的 ID（可以直接叫作图片存储对象 ID）。同时，还要能够根据图片 ID 快速查找到图片存储对象 ID。

典型的“键 - 单值”模式，所以开始使用的是String保存值

```
photo_id: 1101000051
photo_obj_id: 3301000051
```

当数据量特别大时，Redis实例会变大，生成RDB快照时间会变慢，因为会给子线程赋值内存页等，详见Redis基础架构第二章的RDB快照章节。

问题出在String类型消耗的内存空间较多

### **为什么string类型内存开销大**

上面的场景中，实际保存1亿张图片用了6.4GB，平均一个图片ID和图片对象ID就用了64字节；

但是我们知道10位数字完全可以用8字节保存，8字节是64位，2的64次幂完全可以存储10位数，为什么Redis保存两个string需要浪费这么大的空间呢？

#### **SDS**

当保存的数据是一个64位整数时，String真实的结构是一个8字节的Long整数，这种保存方式叫int编码；

当保存的字符串中有字符时，String的真实结构是Redis的SDS（简单动态字符串）

<img src="C:\Users\lcx76\Pictures\image\37c6a8d5abd65906368e7c4a6b938657.jpg" alt="img" style="zoom:25%;" />

- **buf**：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销。
- **len**：占 4 个字节，表示 buf 的已用长度。
- **alloc**：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。

#### **RedisObject**

在Redis中，不同的数据结构有着相同的元数据要记录，比如最后一次被访问的时间、被引用的次数等等，所以Redis使用RedisObject保存元数据信息

RedisObject是一个8+8字节的结构，前8字节保存元数据信息，后8字节是一个指针，指向真实数据的地址

<img src="C:\Users\lcx76\Pictures\image\3409948e9d3e8aa5cd7cafb9b66c2857.jpg" alt="img" style="zoom:25%;" />

#### Redis保存String做的优化

对于Long类型的整数和SDS，Redis做了专门的优化较少内存开销：

- Long类型的整数，RedisObject的指针直接放的就是Long的8字节数据，省去了指针的内存开销
- 小于44字节的SDS，RedisObject和SDS的地址是连续的减少了内存碎片，这种叫embstr编码
- 大于44字节的SDS，就是RedisObject指针指向一块SDS地址那种，叫raw编码

<img src="C:\Users\lcx76\Pictures\image\ce83d1346c9642fdbbf5ffbe701bfbe3.jpg" alt="img" style="zoom:25%;" />

因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节。但是，另外的 32 字节去哪儿了呢？

Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，如下图所示：

<img src="C:\Users\lcx76\Pictures\image\a6708594a86d2a49107f8b6cfc1a2b8a.jpg" alt="img" style="zoom:25%;" />

但是，这三个指针只有 24 字节，为什么会占用了 32 字节呢？这就要提到 Redis 使用的内存分配库 jemalloc 了。

jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。举个例子。如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字节空间，jemalloc 则会分配 32 字节。所以，在我们刚刚说的场景里，dictEntry 结构就占用了 32 字节。

### ziplist压缩列表

Redis有一种底层结构很省内存空间—>压缩列表

<img src="C:\Users\lcx76\Pictures\image\f6d4df5f7d6e80de29e2c6446b02429f.jpg" alt="img" style="zoom:25%;" />

- zlbytes：列表长度
- zltail：列表尾的偏移量
- zllen：列表entry个数
- zlend：表示列表的结尾
- entry：
  - prev_len，表示前一个 entry 的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len 取值为 1 字节，否则，就取值为 5 字节。
  - len：表示自身长度，4 字节；
  - encoding：表示编码方式，1 字节；
  - content：保存实际数据。

Redis基于压缩列表实现了list hash sortedset集合，集合最大好出就是dictEntry开销小，string值是一个值和它的key就是一个dictEntry，使用集合会减少很多dictEntry的个数

### 用集合类型保存单值的键值对

**利用hash类型实现二级编码**

以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value。

```
127.0.0.1:6379> info memory
# Memory
used_memory:1039120
127.0.0.1:6379> hset 1101000 060 3302000080
(integer) 1
127.0.0.1:6379> info memory
# Memory
used_memory:1039136
```

**Redis Hash集合的内部结构实现**

Redis的Hash集合底层是由压缩列表和哈希表实现的

- hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。
- hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。

超过上面两个配置之后，Redis Hash集合就会由压缩列表变为哈希表存储，哈希表是不如压缩列表节省内存空间的，

为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。

### 问题

保存图片的例子，除了用String和Hash存储之外，还可以用Sorted Set存储（勉强）。

Sorted Set与Hash类似，当元素数量少于zset-max-ziplist-entries，并且每个元素内存占用小于zset-max-ziplist-value时，默认也采用ziplist结构存储。我们可以把zset-max-ziplist-entries参数设置为1000，这样Sorted Set默认就会使用ziplist存储了，member和score也会紧凑排列存储，可以节省内存空间。

使用zadd 1101000 3302000080 060命令存储图片ID和对象ID的映射关系，查询时使用zscore 1101000 060获取结果。

但是Sorted Set使用ziplist存储时的缺点是，这个ziplist是需要按照score排序的（为了方便zrange和zrevrange命令的使用），所以在插入一个元素时，需要先根据score找到对应的位置，然后把member和score插入进去，这也意味着Sorted Set插入元素的性能没有Hash高（这也是前面说勉强能用Sorte Set存储的原因）。而Hash在插入元素时，只需要将新的元素插入到ziplist的尾部即可，不需要定位到指定位置。

不管是使用Hash还是Sorted Set，当采用ziplist方式存储时，虽然可以节省内存空间，但是在查询指定元素时，都要遍历整个ziplist，找到指定的元素。所以使用ziplist方式存储时，虽然可以利用CPU高速缓存，但也不适合存储过多的数据（hash-max-ziplist-entries和zset-max-ziplist-entries不宜设置过大），否则查询性能就会下降比较厉害。整体来说，这样的方案就是时间换空间，我们需要权衡使用。

当使用ziplist存储时，我们尽量存储int数据，ziplist在设计时每个entry都进行了优化，针对要存储的数据，会尽量选择占用内存小的方式存储（整数比字符串在存储时占用内存更小），这也有利于我们节省Redis的内存。还有，因为ziplist是每个元素紧凑排列，而且每个元素存储了上一个元素的长度，所以当修改其中一个元素超过一定大小时，会引发多个元素的级联调整（前面一个元素发生大的变动，后面的元素都要重新排列位置，重新分配内存），这也会引发性能问题，需要注意。

另外，使用Hash和Sorted Set存储时，虽然节省了内存空间，但是设置过期变得困难（无法控制每个元素的过期，只能整个key设置过期，或者业务层单独维护每个元素过期删除的逻辑，但比较复杂）。而使用String虽然占用内存多，但是每个key都可以单独设置过期时间，还可以设置maxmemory和淘汰策略，以这种方式控制整个实例的内存上限。

所以在选用Hash和Sorted Set存储时，意味着把Redis当做数据库使用，这样就需要务必保证Redis的可靠性（做好备份、主从副本），防止实例宕机引发数据丢失的风险。而采用String存储时，可以把Redis当做缓存使用，每个key设置过期时间，同时设置maxmemory和淘汰策略，控制整个实例的内存上限，这种方案需要在数据库层（例如MySQL）也存储一份映射关系，当Redis中的缓存过期或被淘汰时，需要从数据库中重新查询重建缓存，同时需要保证数据库和缓存的一致性，这些逻辑也需要编写业务代码实现。

总之，各有利弊，我们需要根据实际场景进行选择。

## 二.Redis数据统计

## 三.GEO地图数据模型

## 四.时间序列数据

### 时间序列数据的场景

一个物联网项目的数据存取需求，和这个很相似。我们需要周期性地统计近万台设备的实时状态，包括设备 ID、压力、温度、湿度，以及对应的时间戳

```
DeviceID, Pressure, Temperature, Humidity, TimeStamp
```

### 时间序列数据读取的特点

- 针对时间序列数据的“写要快”，Redis 的高性能写特性直接就可以满足了；
- 针对“查询模式多”，也就是要支持单点查询、范围查询和聚合计算，Redis 提供了保存时间序列数据的两种方案，分别可以基于 Hash 和 Sorted Set 实现，以及基于 RedisTimeSeries 模块实现。

### 基于Hash的单点查询

Redis哈希键的特点就是可以使用N(1)的时间复杂度通过一个key找到一个value，所以可以使用时间戳做key，温度做value保存时间序列数据，这样单点查询的时候就会很快找到数据

<img src="C:\Users\lcx76\Pictures\image\f2e7bc4586be59aa5e7e78a5599830be.jpg" alt="img" style="zoom:25%;" />

举个例子。我们用 HGET 命令查询 202008030905 这个时刻的温度值，使用 HMGET 查询 202008030905、202008030907、202008030908 这三个时刻的温度值，如下所示：

```
HGET device:temperature 202008030905
"25.1"

HMGET device:temperature 202008030905 202008030907 202008030908
1) "25.1"
2) "25.9"
3) "24.9"
```

但是，哈希键是基于压缩列表和字典实现的，大数据情况下会变成字典，字典的特点是无序的，不适合做范围查找

### 基于Sorted Set做范围查找

<img src="C:\Users\lcx76\Pictures\image\9e1214dbd5b42c5b3452ea73efc8c67a.jpg" alt="img" style="zoom:25%;" />

使用 Sorted Set 保存数据后，我们就可以使用 ZRANGEBYSCORE 命令，按照输入的最大时间戳和最小时间戳来查询这个时间范围内的温度值了。如下所示，我们来查询一下在 2020 年 8 月 3 日 9 点 7 分到 9 点 10 分间的所有温度值：

```

ZRANGEBYSCORE device:temperature 202008030907 202008030910
1) "25.9"
2) "24.9"
3) "25.3"
4) "25.2"
```

### Redis事务简单介绍

现在我们知道了，同时使用 Hash 和 Sorted Set，可以满足单个时间点和一个时间范围内的数据查询需求了，但是我们又会面临一个新的问题，也就是我们要解答的第二个问题：如何保证写入 Hash 和 Sorted Set 是一个原子性的操作呢？

- MULTI 命令：表示一系列原子性操作的开始。收到这个命令后，Redis 就知道，接下来再收到的命令需要放到一个内部队列中，后续一起执行，保证原子性。
- EXEC 命令：表示一系列原子性操作的结束。一旦 Redis 收到了这个命令，就表示所有要保证原子性的命令操作都已经发送完成了。此时，Redis 开始执行刚才放到内部队列中的所有命令操作。

<img src="C:\Users\lcx76\Pictures\image\c0e2fd5834113cef92f2f68e7462a262.jpg" alt="img" style="zoom:25%;" />

```

127.0.0.1:6379> MULTI
OK

127.0.0.1:6379> HSET device:temperature 202008030911 26.8
QUEUED

127.0.0.1:6379> ZADD device:temperature 202008030911 26.8
QUEUED

127.0.0.1:6379> EXEC
1) (integer) 1
2) (integer) 1
```

*在使用MULTI和EXEC命令时，建议客户端使用pipeline，当使用pipeline时，客户端会把命令一次性批量发送给服务端，然后让服务端执行，这样可以减少客户端和服务端的来回网络IO次数，提升访问性能。*

### 基于 RedisTimeSeries 模块做聚合运算

- 用 TS.CREATE 命令创建时间序列数据集合；
- 用 TS.ADD 命令插入数据；
- 用 TS.GET 命令读取最新数据；
- 用 TS.MGET 命令按标签过滤查询数据集合；
- 用 TS.RANGE 支持聚合计算的范围查询。

#### 用 TS.CREATE 命令创建一个时间序列数据集合

在 TS.CREATE 命令中，我们需要设置时间序列数据集合的 key 和数据的过期时间（以毫秒为单位）。此外，我们还可以为数据集合设置标签，来表示数据集合的属性。

例如，我们执行下面的命令，创建一个 key 为 device:temperature、数据有效期为 600s 的时间序列数据集合。也就是说，这个集合中的数据创建了 600s 后，就会被自动删除。最后，我们给这个集合设置了一个标签属性{device_id:1}，表明这个数据集合中记录的是属于设备 ID 号为 1 的数据。

```
TS.CREATE device:temperature RETENTION 600000 LABELS device_id 1
OK
```

#### 用 TS.ADD 命令插入数据，用 TS.GET 命令读取最新数据

我们可以用 TS.ADD 命令往时间序列集合中插入数据，包括时间戳和具体的数值，并使用 TS.GET 命令读取数据集合中的最新一条数据。

例如，我们执行下列 TS.ADD 命令时，就往 device:temperature 集合中插入了一条数据，记录的是设备在 2020 年 8 月 3 日 9 时 5 分的设备温度；再执行 TS.GET 命令时，就会把刚刚插入的最新数据读取出来。

```
TS.ADD device:temperature 1596416700 25.1
1596416700

TS.GET device:temperature 
25.1
```

#### 用 TS.MGET 命令按标签过滤查询数据集合

在保存多个设备的时间序列数据时，我们通常会把不同设备的数据保存到不同集合中。此时，我们就可以使用 TS.MGET 命令，按照标签查询部分集合中的最新数据。在使用 TS.CREATE 创建数据集合时，我们可以给集合设置标签属性。当我们进行查询时，就可以在查询条件中对集合标签属性进行匹配，最后的查询结果里只返回匹配上的集合中的最新数据。

举个例子。假设我们一共用 4 个集合为 4 个设备保存时间序列数据，设备的 ID 号是 1、2、3、4，我们在创建数据集合时，把 device_id 设置为每个集合的标签。此时，我们就可以使用下列 TS.MGET 命令，以及 FILTER 设置（这个配置项用来设置集合标签的过滤条件），查询 device_id 不等于 2 的所有其他设备的数据集合，并返回各自集合中的最新的一条数据。

```
TS.MGET FILTER device_id!=2 
1) 1) "device:temperature:1"
   2) (empty list or set)
   3) 1) (integer) 1596417000
      2) "25.3"
2) 1) "device:temperature:3"
   2) (empty list or set)
   3) 1) (integer) 1596417000
      2) "29.5"
3) 1) "device:temperature:4"
   2) (empty list or set)
   3) 1) (integer) 1596417000
      2) "30.1"
```

#### 用 TS.RANGE 支持需要聚合计算的范围查询

最后，在对时间序列数据进行聚合计算时，我们可以使用 TS.RANGE 命令指定要查询的数据的时间范围，同时用 AGGREGATION 参数指定要执行的聚合计算类型。RedisTimeSeries 支持的聚合计算类型很丰富，包括求均值（avg）、求最大 / 最小值（max/min），求和（sum）等。

例如，在执行下列命令时，我们就可以按照每 180s 的时间窗口，对 2020 年 8 月 3 日 9 时 5 分和 2020 年 8 月 3 日 9 时 12 分这段时间内的数据进行均值计算了。

```
TS.RANGE device:temperature 1596416700 1596417120 AGGREGATION avg 180000
1) 1) (integer) 1596416700
   2) "25.6"
2) 1) (integer) 1596416880
   2) "25.8"
3) 1) (integer) 1596417060
   2) "26.1"
```

### 问题

1. **使用 Sorted Set 保存时间序列数据，把时间戳作为 score，把实际的数据作为 member，你觉得这样保存数据有没有潜在的风险？**

   - sorted set是去重存储，可能会丢失数据，毕竟类似温度这种数据，不同时间完全可能是一致的
   - 如果对某一个对象的时序数据记录很频繁的话，那么这个key很容易变成一个bigkey，在key过期释放内存时可能引发阻塞风险。所以不能把这个对象的所有时序数据存储在一个key上，而是需要拆分存储，例如可以按天/周/月拆分（根据具体查询需求来定）。当然，拆分key的缺点是，在查询时，可能需要客户端查询多个key后再做聚合才能得到结果

2. **另外，如果你是 Redis 的开发维护者，你会把聚合计算也设计为 Sorted Set 的一个内在功能吗？**

   ​		不会。因为聚合计算是CPU密集型任务，Redis在处理请求时是单线程的，也就是它在做聚合计算时无法利用到多核CPU来提升计算速度，如果计算量太大，这也会导致Redis的响应延迟变长，影响Redis的性能。Redis的定位就是高性能的内存数据库，要求访问速度极快。***所以对于时序数据的存储和聚合计算，我觉得更好的方式是交给时序数据库去做，时序数据库会针对这些存储和计算的场景做针对性优化。***

## 五.使用Redis实现的分布式消息队列

### 消息队列的要求

- 消息保序
- 重复消息处理：网络阻塞可能消息重发
- 消息可靠性保证：可能因为宕机故障等，消息没有处理完，消费者重启后消息队列应该能让消费者重新处理未完成的消息

### 基于List的消息队列实现

list是一个先进先出的顺序结构，所有可以使用LPUSH和RPOP命令直接存取数据，BRPOP是阻塞式的读取数据，可以防止空轮询造成CPU消耗

每个消息生成一个唯一ID，消费者保存处理过的消息的ID，通过这种方式来解决重复消息处理问题；但是list本身是不会生成唯一ID的，所以需要生成者把ID包在消息中发给消息队列（list），比如：

```
LPUSH mq "101030001:stock:5"
(integer) 1
```



为了留存消息，List 类型提供了 BRPOPLPUSH 命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。

<img src="C:\Users\lcx76\Pictures\image\5045395da08317b546aab7eb698d013d.jpg" alt="img" style="zoom:25%;" />

​		list做消息队列的不足：假如生产者生产消息的速度特别快，消费者的消费速度跟不上，就会使list中堆积大量的数据，对Redis的内存造成影响，但是list是不支持消费组的。

### Streams解决list的不足

Streams 是 Redis 专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。

1. XADD：插入消息，保证有序，可以自动生成全局唯一 ID；
2. XREAD：用于读取消息，可以按 ID 读取数据；
3. XREADGROUP：按消费组形式读取消息；
4. XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。

具体Stream构造和使用

[基于Redis的Stream类型的完美消息队列解决方案 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/60501638)

[redis — 基于Spring Boot实现Redis stream实时流事件处理_Haqiu.Hwang的博客-CSDN博客](https://blog.csdn.net/qq_38658567/article/details/109376888)

![img](C:\Users\lcx76\Pictures\image\b2d6581e43f573da6218e790bb8c6814.jpg)

​		Redis 是一个非常轻量级的键值数据库，部署一个 Redis 实例就是启动一个进程，部署 Redis 集群，也就是部署多个 Redis 实例。而 Kafka、RabbitMQ 部署时，涉及额外的组件，例如 Kafka 的运行就需要再部署 ZooKeeper。相比 Redis 来说，Kafka 和 RabbitMQ 一般被认为是重量级的消息队列。

​		所以，关于是否用 Redis 做消息队列的问题，不能一概而论，我们需要考虑业务层面的数据体量，以及对性能、可靠性、可扩展性的需求。如果分布式系统中的组件消息通信量不大，那么，Redis 只需要使用有限的内存空间就能满足消息存储的需求，而且，Redis 的高性能特性能支持快速的消息读写，不失为消息队列的一个好的解决方案。

## 六.影响Redis性能的五类因素

1. Redis 内部的阻塞式操作；
2. CPU 核和 NUMA 架构的影响；
3. Redis 关键系统配置；
4. Redis 内存碎片；
5. Redis 缓冲区。

## 七.第一类--Redis内部阻塞操作

### Redis阻塞点

<img src="C:\Users\lcx76\Pictures\image\6ce8abb76b3464afe1c4cb3bbe426922.jpg" alt="img" style="zoom:25%;" />

**Redis实例和客户端交互**

1. 网络IO：Redis的网络IO使用IO复用模型，所以不会成为阻塞点
2. 键值对的增删查改：客户端与Redis服务器交互的主要操作，复杂度为O(N)的复杂操作必将是阻塞点；比如**集合的全量查询和聚合统计计算**
3. bigkey删除：删除操作本质是释放键值对占用的内存空间；内存释放时，操作系统会让释放的内存插入一个空闲内存块的链表中，这个操作会阻塞释放内存的线程；一下子释放大量内存会导致空闲内存链表操作时间增加，阻塞Redis主线程。![img](https://static001.geekbang.org/resource/image/94/53/94bc8cf9yy5c34a6445434a15b1e9653.jpg)
4. 整个数据库的清空操作必将阻塞主线程

**Redis实例与磁盘交互**

1. RDB生成和AOF重写都会有子线程操作，所以不会造成阻塞
2. AOF同步写回：当有大量写命令时，会造成主线程阻塞；一个同步写回的耗时一般是1~2ms

**主从复制**

1. 主库会生成RDB快照，但是由子线程做，所以主库不会阻塞
2. 从库要清空原本的数据库，必将阻塞从库主线程
3. 从库从RDB快照加载数据，RDB文件很大时会很耗时，也会阻塞从库主线程

**切片集群交互**

​		切片集群哈希槽是渐进式迁移，数据少时一般不会阻塞Redis实例；

​		不过，如果你使用了 Redis Cluster 方案，而且同时正好迁移的是 bigkey 的话，就会造成主线程的阻塞，因为 Redis Cluster 使用了同步迁移。

**阻塞点总结**

- 集合全量查询和聚合操作；
- bigkey 删除；
- 清空数据库；
- AOF 日志同步写；
- 从库加载 RDB 文件。

### 哪些阻塞点可以异步执行？

Redis线程关键路径操作：客户端发送命令给主线程，主线程不必立刻回复客户端准确数据的操作。

- 客户端的读命令是典型的关键路径操作，因为需要立刻回复客户端读取到的数据，集合全量查询和聚合操作都涉及到了读操作，所以是不可以异步执行的；

- **删除操作是不必给客户端返回数据结果的，所以可以创建子线程异步执行，所以bigKey删除和清空数据库是可以异步执行的；**

- **同样，AOF同步写回也可以交给子线程做，可以异步执行；**

- 最后，RDB加载，从库肯定要先同步数据才能做其他读操作的，所以这一步肯定要交给主线程加载完，不能异步执行。

### 异步子线程机制

​		Redis主线程启动后，会通过操作系统提供的pthread_create函数创建三个子线程，分别处理AOF写回，键值对数据库删除以及文件关闭的异步执行

​		主线程会让上述三种操作封装成任务，放到一个链表形式的任务队列中，子线程从任务队列中取任务并执行

<img src="C:\Users\lcx76\Pictures\image\ae004728bfe6d3771c7424e4161e7969.jpg" alt="img" style="zoom:25%;" />

**开启异步**的方式

- AOF日志配置成everysec选项

- 键值对删除：UNLINK命令

- 数据库清空：FLUSHDB和FLUSHALL后面加ASYNC

  ```
  	FLUSHDB ASYNC
  	FLUSHALL AYSNC
  ```

异步删除操作是 Redis 4.0 以后才有的功能，Redis 4.0之前的版本，可以使用CSAN命令先查出部分数据，在DEL，将大的bigkey删除分散开，防止阻塞主线程

对于无法异步的集合聚合统计和RDB快照加载：

- 可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算；
- 把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。

## 八.第二类--CPU 核和 NUMA 架构的影响

### 主流CPU多核架构和多CPU架构（NUMA）

**CPU多核架构**

目前主流服务器的CPU都是多物理核心的，而一个物理核心又会开启两个超线程，也叫作逻辑核；L1L2级缓存访问速度特别快，但是成本很高内存较小，所有有了L3级缓存。

CPU的一个物理核心会使用独享L1、L2级缓存（逻辑核共享），多个物理核心共享L3级缓存。

<img src="C:\Users\lcx76\Pictures\image\d9689a38cbe67c3008d8ba99663c2f09.jpg" alt="img" style="zoom:25%;" />

**多CPU架构（NUMA）**

主流的服务器还会使用多CPU架构，每个CPU成为CPU Socket，应用程序会在不同的Socket上运行，通过总线连接不同的CPU；

不同CPU Socket是不会共享内存的，如果一个应用程序运行时切换了CPU Socket，访问内存时应该访问的是之前所在Socket的内存，这就需要总线了，属于远端内存访问，和直接访问当前Socket的内存相比会增加延迟

![img](C:\Users\lcx76\Pictures\image\5ceb2ab6f61c064284c8f8811431bc3d.jpg)

**总结**

- L1、L2 缓存中的指令和数据的访问速度很快，所以，充分利用 L1、L2 缓存，可以有效缩短应用程序的执行时间；
- 在 NUMA 架构下，如果应用程序从一个 Socket 上调度到另一个 Socket 上，就可能会出现远端内存访问的情况，这会直接增加应用程序的执行时间。

### CPU多核架构对Redis性能的影响

在CPU核上运行程序时，应用程序访问最频繁的数据信息，会被加载到L1L2缓存上，以便快速读取；当切换核心后，这些数据要重新缓存到L1、L2缓存上，会影响一部分应用程序的性能，像Redis这种高性能程序会有很大的影响

所以我们需要**核绑定**

```
taskset -c 0 ./redis-server
```

### NUMA架构对Redis性能的影响

**网络中断处理程序与CPU核绑定**

先来看看Redis和网络中断程序的网络交互：

![](C:\Users\lcx76\Pictures\image\8753ce6985fd08bb9cf9a3813c8b2cd2.jpg)

这个做法可以避免网络中断处理程序在不同核上来回调度执行，的确能有效提升 Redis 的网络处理性能。

但是有一个潜在的风险：**如果网络中断处理程序和 Redis 实例各自所绑的 CPU 核不在同一个 CPU Socket 上，那么，Redis 实例读取网络数据时，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间。**

就会变成这样：

<img src="C:\Users\lcx76\Pictures\image\30cd42yy86debc0eb6e7c5b069533ab0.jpg" alt="img" style="zoom:25%;" />

所以，为了避免 Redis 跨 CPU Socket 访问网络数据，我们最好把网络中断程序和 Redis 实例绑在同一个 CPU Socket 上，这样一来，Redis 实例就可以直接从本地内存读取网络数据了，如下图所示：

![img](C:\Users\lcx76\Pictures\image\41f02b2afb08ec54249680e8cac30179.jpg)

不过，需要注意的是，在 CPU 的 NUMA 架构下，对 CPU 核的编号规则，并不是先把一个 CPU Socket 中的所有逻辑核编完，再对下一个 CPU Socket 中的逻辑核编码，而是先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。

```
lscpu

Architecture: x86_64
...
NUMA node0 CPU(s): 0-5,12-17
NUMA node1 CPU(s): 6-11,18-23
...
```

### 绑核存在的风险

风险：绑在一个逻辑核上，会导致Redis主线程和子线程竞争CPU。

方案1：绑定一个物理核上，这样Redis实例就有两个逻辑核可以使用，可以减小一些CPU竞争

```
taskset -c 0,12 ./redis-server
```

方案2：优化 Redis 源码

通过编程实现绑核时，要用到操作系统提供的 1 个数据结构 cpu_set_t 和 3 个函数 CPU_ZERO、CPU_SET 和 sched_setaffinity：

- cpu_set_t 数据结构：是一个位图，每一位用来表示服务器上的一个 CPU 逻辑核。
- CPU_ZERO 函数：以 cpu_set_t 结构的位图为输入参数，把位图中所有的位设置为 0。
- CPU_SET 函数：以 CPU 逻辑核编号和 cpu_set_t 位图为参数，把位图中和输入的逻辑核编号对应的位设置为 1。
- sched_setaffinity 函数：以进程 / 线程 ID 号和 cpu_set_t 为参数，检查 cpu_set_t 中哪一位为 1，就把输入的 ID 号所代表的进程 / 线程绑在对应的逻辑核上。

**Redis 6.0提供了配置的方式**

### 问题

在一台有2个CPU Socket（每个Socket 8个物理核）的服务器上，我们部署了有8个实例的Redis切片集群（8个实例都为主节点，没有主备关系），采用哪种方案绑核最佳？

我更倾向于的方案是：在两个CPU Socket上各运行4个实例，并和相应Socket上的核绑定。这么做的原因主要从L3 Cache的命中率、内存利用率、避免使用到Swap这三个方面考虑：

1、由于CPU Socket1和2分别有自己的L3 Cache，如果把所有实例都绑定在同一个CPU Socket上，相当于这些实例共用这一个L3 Cache，另一个CPU Socket的L3 Cache浪费了。这些实例共用一个L3 Cache，会导致Cache中的数据频繁被替换，访问命中率下降，之后只能从内存中读取数据，这会增加访问的延迟。而8个实例分别绑定CPU Socket，可以充分使用2个L3 Cache，提高L3 Cache的命中率，减少从内存读取数据的开销，从而降低延迟。

2、如果这些实例都绑定在一个CPU Socket，由于采用NUMA架构的原因，所有实例会优先使用这一个节点的内存，当这个节点内存不足时，再经过总线去申请另一个CPU Socket下的内存，此时也会增加延迟。而8个实例分别使用2个CPU Socket，各自在访问内存时都是就近访问，延迟最低。

3、如果这些实例都绑定在一个CPU Socket，还有一个比较大的风险是：用到Swap的概率将会大大提高。如果这个CPU Socket对应的内存不够了，也可能不会去另一个节点申请内存（操作系统可以配置内存回收策略和Swap使用倾向：本节点回收内存/其他节点申请内存/内存数据换到Swap的倾向程度），而操作系统可能会把这个节点的一部分内存数据换到Swap上从而释放出内存给进程使用（如果没开启Swap可会导致直接OOM）。因为Redis要求性能非常高，如果从Swap中读取数据，此时Redis的性能就会急剧下降，延迟变大。所以8个实例分别绑定CPU Socket，既可以充分使用2个节点的内存，提高内存使用率，而且触发使用Swap的风险也会降低。

其实我们可以查一下，在NUMA架构下，也经常发生某一个节点内存不够，但其他节点内存充足的情况下，依旧使用到了Swap，进而导致软件性能急剧下降的例子。所以在运维层面，我们也需要关注NUMA架构下的内存使用情况（多个内存节点使用可能不均衡），并合理配置系统参数（内存回收策略/Swap使用倾向），尽量去避免使用到Swap。

## 九.第三类--一些系统配置和操作系统的影响

### 如何判断Redis变慢

- 查看Redis延迟，一般Redis延迟很小，只要某一时刻延迟达到几秒就可以判断Redis变慢了
- Redis基线性能：Redis延迟是基线性能的2倍就可以判定Redis变慢了
- 网络性能：使用iPref工具等

**基线性能**

从 2.8.7 版本开始，redis-cli 命令提供了–intrinsic-latency 选项，可以用来监测和统计测试期间内的最大延迟，这个延迟可以作为 Redis 的基线性能

```
./redis-cli --intrinsic-latency 120
Max latency so far: 17 microseconds.
Max latency so far: 44 microseconds.
Max latency so far: 94 microseconds.
Max latency so far: 110 microseconds.
Max latency so far: 119 microseconds.

36481658 total runs (avg latency: 3.2893 microseconds / 3289.32 nanoseconds per run).
Worst run took 36x longer than the average latency.
```

### 如何应对Redis变慢

![img](C:\Users\lcx76\Pictures\image\cd026801924e197f5c79828c368cd706.jpg)

三块红色区域是造成Redis性能延迟的主要三个要素

#### Redis自身操作特性

**慢查询**

慢查询指的是Redis中执行速度慢的命令，和命令底层实现函数的时间复杂度关

可以通过Redis日志或者latency monitor工具，查看变慢的请求，根据请求的命令去查看是否是复杂度较高的命令，有三种方法可以避免慢查询：

- 用其他高效命令替代：如返回一个SET中所有数据时，不要使用SMEMBERS，而是使用SSCAN多次迭代返回
- 当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。业务不要使用KEYS命令。
- 业务上实在要用慢查询命令，只能使用性能更好的CPU了

**大量过期key删除**

Redis 键值对的 key 可以设置过期时间。默认情况下，Redis 每 100 毫秒会删除一些过期 key，具体的算法如下：

1. 采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除；
2. 如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。

第一种情况下， ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 一般不大可以设置默认20，所以一次删除的key不会很多，但是如果设置了大量的同一时间过期的key可能会造成第二种情况，一直在删除过期key，造成长时间阻塞，删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）

### 问题

在 Redis 中，还有哪些其他命令可以代替 KEYS 命令，实现同样的功能呢？这些命令的复杂度会导致 Redis 变慢吗？

如果想要获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行SCAN $cursor COUNT $count可以得到一批key以及下一个游标$cursor，然后把这个$cursor当作SCAN的参数，再次执行，以此往复，直到返回的$cursor为0时，就把整个实例中的所有key遍历出来了。

关于SCAN讨论最多的问题就是，Redis在做Rehash时，会不会漏key或返回重复的key。

在使用SCAN命令时，不会漏key，但可能会得到重复的key，这主要和Redis的Rehash机制有关。Redis的所有key存在一个全局的哈希表中，如果存入的key慢慢变多，在达到一定阈值后，为了避免哈希冲突导致查询效率降低，这个哈希表会进行扩容。与之对应的，key数量逐渐变少时，这个哈希表会缩容以节省空间。

1、为什么不会漏key？Redis在SCAN遍历全局哈希表时，采用*高位进位法*的方式遍历哈希桶（可网上查询图例，一看就明白），当哈希表扩容后，通过这种算法遍历，旧哈希表中的数据映射到新哈希表，依旧会保留原来的先后顺序，这样就可以保证遍历时不会遗漏也不会重复。

2、为什么SCAN会得到重复的key？这个情况主要发生在哈希表缩容。已经遍历过的哈希桶在缩容时，会映射到新哈希表没有遍历到的位置，所以继续遍历就会对同一个key返回多次。

SCAN是遍历整个实例的所有key，另外Redis针对Hash/Set/Sorted Set也提供了HSCAN/SSCAN/ZSCAN命令，用于遍历一个key中的所有元素，建议在获取一个bigkey的所有数据时使用，避免发生阻塞风险。

但是使用HSCAN/SSCAN/ZSCAN命令，返回的元素数量与执行SCAN逻辑可能不同。执行SCAN $cursor COUNT $count时一次最多返回count个数的key，数量不会超过count。

但Hash/Set/Sorted Set元素数量比较少时，底层会采用intset/ziplist方式存储，如果以这种方式存储，在执行HSCAN/SSCAN/ZSCAN命令时，会无视count参数，直接把所有元素一次性返回，也就是说，得到的元素数量是会大于count参数的。当底层转为哈希表或跳表存储时，才会真正使用发count参数，最多返回count个元素。

### 文件系统：AOF模型下的阻塞

**AOF写回策略的延迟**

AOF日志有三种写回策略，其实这三种写回策略调用了两个文件系统函数，write和fsync

![img](C:\Users\lcx76\Pictures\image\9f1316094001ca64c8dfca37c2c49ea4.jpg)

**write 只要把日志记录写到内核缓冲区，就可以返回了，并不需要等待日志实际写回到磁盘；**

**fsync 需要把日志记录写回到磁盘后才能返回，时间较长**

使用everysec和always策略需要使用fsync，但是两种写回策略也有一点区别：

- everysec模式，Redis允许丢失一秒的操作记录，并不需要每个操作记录日志都写回磁盘，当写回策略配置为 everysec 时，Redis 会使用后台的子线程异步完成 fsync 的操作。
- always策略，Redis需要确保每个命令都要写回磁盘，不会使用子线程。

**AOF重写与fsync同时写磁盘造成的延迟**

AOF重写文件较大时肯定会有阻塞，所以Redis 使用子进程来进行 AOF 重写。

AOF重写文件较大时，可能会占用大量磁盘IO宽带，fsync也是要写磁盘的，这时候就会阻塞fsync；要知道及时是子线程在执行fsync，但是主线程会检查fsync的执行情况，如果上一次的写回还没完成，这时候主线程是要阻塞的。

![img](C:\Users\lcx76\Pictures\image\2a47b3f6fd7beaf466a675777ebd28a6.jpg)

**结论**

由于 fsync 后台子线程和 AOF 重写子进程的存在，主 IO 线程一般不会被阻塞。但是，如果在重写日志时，AOF 重写子进程的写入量比较大，fsync 线程也会被阻塞，进而阻塞主线程，导致延迟增加。

**解决方案**

1. 有的业务场景比如Redis做缓存，不需要数据可靠性要求，可以使用NO策略
2. 如果业务应用对延迟非常敏感，但同时允许一定量的数据丢失，那么可以修改配置no-appendfsync-on-rewrite 设置为yes；这个配置项设置为 yes 时，表示在 AOF 重写时，不进行 fsync 操作。
3. 如果的确需要高性能，同时也需要高可靠数据保证，我建议你考虑采用高速的固态硬盘作为 AOF 日志的写入设备

### 操作系统：swap

如果 Redis 的 AOF 日志配置只是 no，或者就没有采用 AOF 模式，那么，还会有什么问题导致性能变慢吗？

潜在的瓶颈：**操作系统的内存 swap。**

内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，涉及到磁盘的读写，所以，一旦触发 swap，无论是被换入数据的进程，还是被换出数据的进程，其性能都会受到慢速磁盘读写的影响。

正常情况下，Redis 的操作是直接通过访问内存就能完成，一旦 swap 被触发了，Redis 的请求操作需要等到磁盘数据读写完成才行。而且，和我刚才说的 AOF 日志文件读写使用 fsync 线程不同，swap 触发后影响的是 Redis 主 IO 线程，这会极大地增加 Redis 的响应时间。

通常，触发 swap 的原因主要是物理机器内存不足，对于 Redis 而言，有两种常见的情况：

- Redis 实例自身使用了大量的内存，导致物理机器的可用内存不足；
- 和 Redis 实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给 Redis 实例的内存量变少，进而触发 Redis 发生 swap。

针对这个问题，我也给你提供一个解决思路：**增加机器的内存或者使用 Redis 集群**。



**如何查看Redis有多少SWAP交换**

先查Redis进程号

```
$ redis-cli info | grep process_id
process_id: 5332
```

进入 Redis 所在机器的 /proc 目录下的该进程目录中：

```
$ cd /proc/5332
```

最后，运行下面的命令，查看该 Redis 进程的使用情况

```
$cat smaps | egrep '^(Swap|Size)'
Size: 584 kB
Swap: 0 kB
Size: 4 kB
Swap: 4 kB
Size: 4 kB
Swap: 0 kB
Size: 462044 kB
Swap: 462008 kB
Size: 21392 kB
Swap: 0 kB
```

可以看到其实使用的都是一块一块的内存块，多大的都有，

Swap: 462008 kB这个就已经是有点问题了，几乎这块内存全都到磁盘上了



如果该实例正好是 Redis 主从集群中的主库，而从库的内存很大，也可以考虑进行主从切换，把大内存的从库变成主库，由它来处理客户端请求。

### 操作系统：内存大页

除了内存 swap，还有一个和内存相关的因素，即内存大页机制（Transparent Huge Page, THP），也会影响 Redis 性能。

由于Redis做持久化的时候，使用写时复制技术，子线程和主线程其实在持久化过程中大部分时间是通用内存的，当有写命令时，主线程会拷贝一块内存和子线程实现内存分离防止给子线程造成影响。

内存大页技术，使得主线程执行一个简单的字符串写操作时也会复制一个2MB的大页，当写入操作哦多时，会造成大量的大页拷贝，会造成延迟。

查看内存大页是否启动：

```
cat /sys/kernel/mm/transparent_hugepage/enabled
```

结果是 always，就表明内存大页机制被启动了；如果是 never，就表示，内存大页机制被禁止。

关闭内存大页：

```
echo never /sys/kernel/mm/transparent_hugepage/enabled
```

### 问题

关于如何分析、排查、解决Redis变慢问题，我总结的checklist如下：

1、使用复杂度过高的命令（例如SORT/SUION/ZUNIONSTORE/KEYS），或一次查询全量数据（例如LRANGE key 0 N，但N很大）

分析：a) 查看slowlog是否存在这些命令 b) Redis进程CPU使用率是否飙升（聚合运算命令导致）

解决：a) 不使用复杂度过高的命令，或用其他方式代替实现（放在客户端做） b) 数据尽量分批查询（LRANGE key 0 N，建议N<=100，查询全量数据建议使用HSCAN/SSCAN/ZSCAN）

2、操作bigkey

分析：a) slowlog出现很多SET/DELETE变慢命令（bigkey分配内存和释放内存变慢） b) 使用redis-cli -h $host -p $port --bigkeys扫描出很多bigkey

解决：a) 优化业务，避免存储bigkey b) Redis 4.0+可开启lazy-free机制

3、大量key集中过期

分析：a) 业务使用EXPIREAT/PEXPIREAT命令 b) Redis info中的expired_keys指标短期突增

解决：a) 优化业务，过期增加随机时间，把时间打散，减轻删除过期key的压力 b) 运维层面，监控expired_keys指标，有短期突增及时报警排查

4、Redis内存达到maxmemory

分析：a) 实例内存达到maxmemory，且写入量大，淘汰key压力变大 b) Redis info中的evicted_keys指标短期突增

解决：a) 业务层面，根据情况调整淘汰策略（随机比LRU快） b) 运维层面，监控evicted_keys指标，有短期突增及时报警 c) 集群扩容，多个实例减轻淘汰key的压力

5、大量短连接请求

分析：Redis处理大量短连接请求，TCP三次握手和四次挥手也会增加耗时

解决：使用长连接操作Redis

6、生成RDB和AOF重写fork耗时严重

分析：a) Redis变慢只发生在生成RDB和AOF重写期间 b) 实例占用内存越大，fork拷贝内存页表越久 c) Redis info中latest_fork_usec耗时变长

解决：a) 实例尽量小 b) Redis尽量部署在物理机上 c) 优化备份策略（例如低峰期备份） d) 合理配置repl-backlog和slave client-output-buffer-limit，避免主从全量同步 e) 视情况考虑关闭AOF f) 监控latest_fork_usec耗时是否变长

7、AOF使用awalys机制

分析：磁盘IO负载变高

解决：a) 使用everysec机制 b) 丢失数据不敏感的业务不开启AOF

8、使用Swap

分析：a) 所有请求全部开始变慢 b) slowlog大量慢日志 c) 查看Redis进程是否使用到了Swap

解决：a) 增加机器内存 b) 集群扩容 c) Swap使用时监控报警

9、进程绑定CPU不合理

分析：a) Redis进程只绑定一个CPU逻辑核 b) NUMA架构下，网络中断处理程序和Redis进程没有绑定在同一个Socket下

解决：a) Redis进程绑定多个CPU逻辑核 b) 网络中断处理程序和Redis进程绑定在同一个Socket下

10、开启透明大页机制

分析：生成RDB和AOF重写期间，主线程处理写请求耗时变长（拷贝内存副本耗时变长）

解决：关闭透明大页机制

11、网卡负载过高

分析：a) TCP/IP层延迟变大，丢包重传变多 b) 是否存在流量过大的实例占满带宽

解决：a) 机器网络资源监控，负载过高及时报警 b) 提前规划部署策略，访问量大的实例隔离部署

总之，Redis的性能与CPU、内存、网络、磁盘都息息相关，任何一处发生问题，都会影响到Redis的性能。

主要涉及到的包括业务使用层面和运维层面：业务人员需要了解Redis基本的运行原理，使用合理的命令、规避bigke问题和集中过期问题。运维层面需要DBA提前规划好部署策略，预留足够的资源，同时做好监控，这样当发生问题时，能够及时发现并尽快处理。

## 十.第四类--内存碎片的影响

### 内存碎片的形成原因

内因：内存分配器的分配策略

外因：Redis键值对大小不一和Redis键值对删除问题

### 使用INFO命令查看Redis内存

```
INFO memory
# Memory
used_memory:1073741736
used_memory_human:1024.00M
used_memory_rss:1997159792
used_memory_rss_human:1.86G
…
mem_fragmentation_ratio:1.86
```

mem_fragmentation_ratio指标就是Redis当前内存碎片率，其实就是使用used_memory_rss和used_memory计算出来的：

```
mem_fragmentation_ratio = used_memory_rss/ used_memory
```

used_memory_rss就是操作系统实际分配给Redis的物理内存空间，包含碎片；

used_memory是Redis保存数据实际使用的内存

一般来说

1<mem_fragmentation_ratio<1.5  : 是正常的

mem_fragmentation_ratio>1.5 就要清理内存碎片了

### Redis清理内存碎片

Redis在4.0-RC3之后提供了一套内存碎片清理机制

首先需要设置

```
config set activedefrag yes
```

这个配置只是告诉Redis可以进行碎片清理，但是什么时候开始清理受一下两个参数影响：

- **active-defrag-ignore-bytes 100mb**：表示内存碎片的字节数达到 100MB 时，开始清理；
- **active-defrag-threshold-lower 10**：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。

当且仅当两个参数都满足时才清理碎片

为了保证Redis性能，还有监控清理操作占用CPU时间，有两个参数通过占用CPU时间控制Redis清理操作

- **active-defrag-cycle-min 25**： 表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展；
- **active-defrag-cycle-max 75**：表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。

## 十一.第五类--内存缓冲区的影响

### 客户端输入和输出缓冲区

为了避免客户端和服务器端发送命令及处理命令的速度不对等，服务器端给每个客户端设置了一个输入缓冲区和一个输出缓冲区

![img](C:\Users\lcx76\Pictures\image\b86be61e91bd7ca207989c220991fce4.jpg)

### 应对客户端输入缓冲区溢出

客户端输入缓冲区是存储客户端发过来的命令的，所以造成客户端缓冲区溢出不外乎两种情况：

1. **写入了bigkey**，比如一下子写入了多个百万级别的集合类型数据
2. **服务器处理命令过慢**，例如Redis主线程出现了间歇性阻塞，无法及时处理发过来的请求，导致客户端发过来的请求堆积在输入缓冲区中



**如何查看输入缓冲区内存使用情况**

使用CLIENT LIST命令

```
CLIENT LIST

id=5 addr=127.0.0.1:50487 fd=9 name= age=4 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client
```

- addr表示客户端的链接信息，如果有多个客户端会出现多个ip和端口
- cmd表示客户端最新执行的命令，例子中最新的命令是client
- qbuf表示客户端输入缓冲区已经使用内存大小，例子中表示使用了26字节
- qbuf-free表示输入缓冲区尚未使用的大小，qbuf和qbuf-free加一起就是客户端缓冲区的总和，例子中26 + 32742 = 32768 字节，也就是 32KB 的缓冲区。

如果qbuf很大同时qbuf-free很小就需要注意了，客户端输入缓冲区在Redis代码中写死最大1G，超过1G Redis的做法是关闭客户端。

同时，Redis服务器一般会有多个客户端，如果客户端占用的内存总和大于Redis设置的maxmemory时，就会触发Redis数据淘汰策略，数据淘汰后只能去底层数据库（如果有底层数据库的话）中查询，降低了业务程序的性能；而且有可能造成内存溢出问题导致Redis整体崩溃。

既然Redis设定的客户端输入缓冲区最大就是1G不可变，那么只能通过命令发送和处理的层面去防止输入缓冲区溢出了，**也就是前面提到的避免客户端写入 bigkey，以及避免 Redis 主线程阻塞。**

### 应对客户端输出缓冲区溢出

Redis客户端输出缓冲区存储的是 主线程处理命令之后返回给客户端的数据，一般有：

1. 简单且大小固定的OK响应（执行SET命令）或者报错信息
2. 大小不固定，包含具体数据的命令（执行HGET命令）

所以，客户端输出缓冲区也有包含两部分：

1. 大小为16K的固定缓冲区，存储OK和报错信息
2. 大小动态可变的缓冲区，存储具体数据结果

会造成输出缓冲区溢出的情况大概有3点：

1. 服务器返回bigkey
2. 执行MONITOR
3. 缓冲区大小设置不合理

其中，返回bigkey查询只能尽量避免，不可调控



MONITOR命令的作用是持续输出监控到的Redis执行的命令

```
MONITOR
OK
1600617456.437129 [0 127.0.0.1:50487] "COMMAND"
1600617477.289667 [0 127.0.0.1:50487] "info" "memory"
```

到这里，你有没有看出什么问题呢？MONITOR 的输出结果会持续占用输出缓冲区，并越占越多，最后的结果就是发生溢出。所以，我要给你一个小建议：**MONITOR 命令主要用在调试环境中，不要在线上生产环境中持续使用 MONITOR。**当然，如果在线上环境中偶尔使用 MONITOR 检查 Redis 的命令执行情况，是没问题的。



和输入缓冲区不同，输出缓冲区可以通过client-output-buffer-limit 来设置：

1. 设置缓冲区大小的上限阈值；
2. 设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值。

```
client-output-buffer-limit normal 0 0 0
```

normal表示普通的客户端，其实Redis的客户端可以有大概3类：

- 和服务端进行读写命令交互的普通客户端，normal
- 订阅了Redis频道的订阅客户端，pubsub
- 以及主从集群中的从节点也算是主节点的客户端，

对于normal来说，发送一个命令之后会等待结果返回，这是阻塞客户端，这种情况下只要不是读取bigkey，那么输出缓冲区一般不会溢出，所以client-output-buffer-limit可以设置为 0 0 0 ，第 1 个 0 设置的是缓冲区大小限制，第 2 个 0 和第 3 个 0 分别表示缓冲区持续写入量限制和持续写入时间限制，其实就是不限制的意思。

对于pubsub客户端来说，一旦订阅的Redis频道有消息了，Redis服务器就会将订阅的消息发送到输出缓冲区，这种是不阻塞的，因此，我们会给订阅客户端设置缓冲区大小限制、缓冲区持续写入量限制，以及持续写入时间限制，可以在 Redis 配置文件中这样设置：

```
client-output-buffer-limit pubsub 8mb 2mb 60
```

这种表示，输出缓冲区最大是8M，一旦实际写入缓冲区中的数据超过8M就要关闭客户端连接了；2M 60表示 如果连续 60 秒内对输出缓冲区的写入量超过 2MB 的话，服务器端也会关闭客户端连接。

总结：

- 避免 bigkey 操作返回大量数据结果；
- 避免在线上环境中持续使用 MONITOR 命令。
- 使用 client-output-buffer-limit 设置合理的缓冲区大小上限，或是缓冲区连续写入时间和写入量上限。

### 主从集群的缓冲区

**复制缓冲区**

主从全量复制时，从库恢复RDB这段时间，主库会将命令写到复制缓冲区中，为了避免缓冲区溢出，

一方面，我们可以将主库实例大小限制到一定大小，比如2-4G，可以加快RDB恢复；

另一方面，可以在主节点设置复制缓冲区的大小，执行以下命令：

```
config set client-output-buffer-limit slave 512mb 128mb 60
```

**复制积压缓冲区**

主节点发送命令给从节点的同时，会将命令写到复制积压缓冲区，等从节点断联恢复之后从复制积压缓冲区增量恢复数据，就是repl_backlog_buffer这个缓冲区。

repl_backlog_buffer是覆盖的几乎不会造成溢出，同时还可以用repl_backlog_size设置大小

### 问题

应用程序和Redis实例交互时，应用程序中使用的客户端需要使用缓冲区吗？如果使用的话，对Redis的性能和内存使用有什么影响？

客户端需要使用缓冲区，好处如下。

1、客户端和服务端交互，一般都会制定一个交互协议，客户端给服务端发数据时，都会按照这个协议把数据拼装好，然后写到客户端buffer中，客户端再一次性把buffer数据写到操作系统的网络缓冲区中，最后由操作系统发送给服务端。这样服务端就能从网络缓冲区中读取到一整块数据，然后按照协议解析数据即可。使用buffer发送数据会比一个个发送数据到服务端效率要高很多。

2、客户端还可以使用Pipeline批量发送命令到服务端，以提高访问性能。不使用Pipeline时，客户端是发送一个命令、读取一次结果。而使用Pipeline时，客户端先把一批命令暂存到buffer中，然后一次性把buffer中的命令发送到服务端，服务端处理多个命令后批量返回结果，这样做的好处是可以减少来回网络IO的次数，降低延迟，提高访问性能。当然，Redis服务端的buffer内存也会相应增长，可以控制好Pipeline命令的数量防止buffer超限。

缓冲区其实无处不在，客户端缓冲区、服务端缓冲区、操作系统网络缓冲区等等，凡是进行数据交互的两端，一般都会利用缓冲区来降低两端速度不匹配的影响。没有缓冲区，就好比一个个工人搬运货物到目的地，每个工人不仅成本高，而且运输效率低。而有了缓冲区后，相当于把这些货物先装到一个集装箱里，然后以集装箱为单位，开车运送到目的地，这样既降低了成本，又提高了运输效率。缓冲区相当于把需要运送的零散数据，进行一块块规整化，然后分批运输。

另外，关于Redis服务端为客户端分配的输出缓冲区，我想补充一点：主库上的从库输出缓冲区（slave client-output-buffer）是不计算在Redis使用的总内存中的，也就是说主从同步延迟，数据积压在主库上的从库输出缓冲区中，这个缓冲区内存占用变大，不会超过maxmemory导致淘汰数据。只有普通客户端和订阅客户端的输出缓冲区内存增长，超过maxmemory时，才会淘汰数据。

# Redis缓存应用

## 一.Redis缓存的工作机制

### 缓存的特征

![img](C:\Users\lcx76\Pictures\image\7dyycf727f9396eb9788644474855a44.jpg)

可以看到缓存存在的必要就是加快数据访问，CPU中的LLC缓存了内存中的数据，内存中得到page cache缓存了磁盘中的数据

所以缓存的**第一个特征**就是：在一个层次化的系统中，缓存就是一个快速子系统，它能存储一部分慢速子系统中的数据，避免每次都从慢速子系统中取数据拖累整个系统，Redis数据访问性能很高，很适合做底层数据库的缓存

同时，llc的容量肯定比内存小，page cache的容量也比磁盘小很多，所以缓存的**第二特征**就是：要比慢速子系统的容量小很多，不可能把所有的数据都放到缓存中，这也造成了缓存必须有数据淘汰策略，Redis是本身就具有淘汰策略的，这也让Redis很适合做缓存

### Redis缓存操作

- 缓存命中：Redis 中有相应数据，就直接读取 Redis，性能非常快。
- 缓存缺失：Redis 中没有保存相应数据，就从后端数据库中读取数据，性能就会变慢。而且，一旦发生缓存缺失，为了让后续请求能从缓存中读取到数据，我们需要把缺失的数据写入 Redis，这个过程叫作缓存更新。缓存更新操作会涉及到保证缓存和数据库之间的数据一致性问题

![img](C:\Users\lcx76\Pictures\image\6b0b489ec0c1c5049c8df84d77fa243d.jpg)

### Redis作为旁路缓存使用

LLC和page cache的方式和Redis做缓存是不一样的，Redis是独立的系统，可以单独优化，但是需要有单独的应用程序去调度，也就是要写get set的代码，这种叫旁路缓存

那么，使用 Redis 缓存时，具体来说，我们需要在应用程序中增加三方面的代码：

- 当应用程序需要读取数据时，我们需要在代码中显式调用 Redis 的 GET 操作接口，进行查询；
- 如果缓存缺失了，应用程序需要再和数据库连接，从数据库中读取数据；
- 当缓存中的数据需要更新时，我们也需要在应用程序中显式地调用 SET 操作接口，把更新的数据写入缓存。

比如：

```
String cacheKey = “productid_11010003”;
String cacheValue = redisCache.get(cacheKey)；
//缓存命中
if ( cacheValue != NULL)
   return cacheValue;
//缓存缺失
else
   cacheValue = getProductFromDB();
   redisCache.put(cacheValue)  //缓存更新
```

### 缓存类型：只读缓存和读写缓存

**只读缓存**

- 读取数据：调用Redis GET命令，缓存命中返回数据，缓存缺失从数据库加载数据到Redis
- 删改数据：直接在数据库中操作，如果Redis缓存中有数据会同时删除保持一致性，下次读取该数据时再从数据库加载数据到Redis

![img](C:\Users\lcx76\Pictures\image\464ea24a098c87b9d292cf61a2b2fecd.jpg)

只读缓存的好处是：数据库中是最新的数据，不会丢失数据，如果业务是读取图片视频等只读数据可以使用只读缓存

**读写缓存**

读写缓存和只读缓存的区别就是删改也会发给Redis，得益于Redis的高性能访问特性，读写缓存的所有操作都能快速给业务应用回应

带来的问题就是Redis是内存数据库，有宕机丢失数据的风险所以要有写回数据库的策略，写回策略大体都是两类：**保证访问性能（同步直写）**和**保证数据可靠性（异步写回）**

- 同步直写：写请求发给Redis的同时也会发给后端数据库，Redis和数据库都写完数据才给客户端返回，浪费了Redis的高性能，但是保证数据几乎不丢失
- 异步写回：写命令只发给Redis，等Redis淘汰数据的时候才写回底层数据库，性能高但是数据可能丢失

![img](C:\Users\lcx76\Pictures\image\009d055bb91d42c28b9316c649f87f66.jpg)

总结：

关于是选择只读缓存，还是读写缓存，主要看我们对写请求是否有加速的需求。

1. 如果需要对写请求进行加速，我们选择读写缓存；
2. 如果写请求很少，或者是只需要提升读请求的响应速度的话，我们选择只读缓存。

### 问题

Redis只读缓存和使用直写策略的读写缓存，这两种缓存都会把数据同步写到后端数据库中，它们的区别在于：

1、使用只读缓存时，是先把修改写到后端数据库中，再把缓存中的数据删除。当下次访问这个数据时，会以后端数据库中的值为准，重新加载到缓存中。这样做的优点是，数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。缺点是每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。

2、使用读写缓存时，是同时修改数据库和缓存中的值。这样做的优点是，被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存，不用再从后端数据库中查询，这个过程拥有比较好的性能，比较适合先修改又立即访问的业务场景。但缺点是在高并发场景下，如果存在多个操作同时修改同一个值的情况，可能会导致缓存和数据库的不一致。

3、当使用只读缓存时，如果修改数据库失败了，那么缓存中的数据也不会被删除，此时数据库和缓存中的数据依旧保持一致。而使用读写缓存时，如果是先修改缓存，后修改数据库，如果缓存修改成功，而数据库修改失败了，那么此时数据库和缓存数据就不一致了。如果先修改数据库，再修改缓存，也会产生上面所说的并发场景下的不一致。

我个人总结，只读缓存是牺牲了一定的性能，优先保证数据库和缓存的一致性，它更适合对于一致性要求比较要高的业务场景。而如果对于数据库和缓存一致性要求不高，或者不存在并发修改同一个值的情况，那么使用读写缓存就比较合适，它可以保证更好的访问性能。

## 二.Redis缓存的大小和淘汰策略

### 缓存大小多少合适

建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。

```
CONFIG SET maxmemory 4gb
```

### Redis内存淘汰策略

目前Redis一共8种内存淘汰策略，按照是否会进行数据淘汰可以分成两种：

1. 不进行数据淘汰的策略，只有noevicition一种
2. 其余7种会进行数据淘汰的策略

7种会进行数据淘汰的策略，根据淘汰候选数据集的范围又可以分为两类：

1. 淘汰设置过期时间数据的策略：volatile-random、volatile-ttl、volatile-lru、volatile-lfu（4.0新增）
2. 在所有数据范围内进行淘汰：allkeys-random、allkeys-lru、allkeys-lfu（4.0新增）

![img](C:\Users\lcx76\Pictures\image\04bdd13b760016ec3b30f4b02e133df6.jpg)

- **noevicition**：Redis默认数据淘汰策略，Redis使用的内存超过maxmemory时不会淘汰数据，而是报错拒绝新数据写入，这种**不适合用做缓存**，缓存总是有新数据写入的；
- **volatile-ttl** 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。
- **volatile-random** 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。
- **volatile-lru** 会使用 LRU 算法筛选设置了过期时间的键值对。
- **volatile-lfu** 会使用 LFU 算法选择设置了过期时间的键值对。
- **allkeys-random** 策略，从所有键值对中随机选择并删除数据；
- **allkeys-lru** 策略，使用 LRU 算法在所有数据中进行筛选。
- **allkeys-lfu** 策略，使用 LFU 算法在所有数据中进行筛选。



lRU算法需要一个链表来维持数据的被访问先后顺序，Redis的做法是在每个RedisObject（键值对数据结构）上多加一个字段lru记录最近一个访问的时间戳

每次要数据淘汰时，选出maxmemory-samples个数据，作为一个候选集合

```
CONFIG SET maxmemory-samples 100
```

比较候选集合中每个数据的lru，淘汰最小的那个；

当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是：**能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。**



**实践建议**

- **优先使用 allkeys-lru 策略**。这样，可以充分利用 LRU 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。如果你的业务数据中有明显的冷热数据区分，我建议你使用 allkeys-lru 策略。
- 如果业务应用中的数据访问频率相差不大，**没有明显的冷热数据区分，建议使用 allkeys-random 策**略，随机选择淘汰的数据就行。
- **如果你的业务中有置顶的需求，比如置顶新闻、置顶视频，那么，可以使用 volatile-lru 策略**，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 LRU 规则进行筛选。



缓存内存淘汰后，干净的数据可以直接删除，脏数据需要写回数据库。对于Redis来说，它会直接删除数据不管是否是脏数据，所以我们设计缓存的时候，要自己把脏数据写回数据库不能依靠Redis

### 问题

Redis在用作缓存时，使用只读缓存或读写缓存的哪种模式？

1、**只读缓存模式**：每次修改直接写入后端数据库，如果Redis缓存不命中，则什么都不用操作，如果Redis缓存命中，则删除缓存中的数据，待下次读取时从后端数据库中加载最新值到缓存中。

2、**读写缓存模式+同步直写策略**：由于Redis在淘汰数据时，直接在内部删除键值对，外部无法介入处理脏数据写回数据库，所以使用Redis作读写缓存时，只能采用同步直写策略，修改缓存的同时也要写入到后端数据库中，从而保证修改操作不被丢失。但这种方案在并发场景下会导致数据库和缓存的不一致，需要在特定业务场景下或者配合分布式锁使用。

当一个系统引入缓存时，需要面临最大的问题就是，如何保证缓存和后端数据库的一致性问题，最常见的3个解决方案分别是Cache Aside、Read/Write Throught和Write Back缓存更新策略。

1、Cache Aside策略：就是文章所讲的只读缓存模式。读操作命中缓存直接返回，否则从后端数据库加载到缓存再返回。写操作直接更新数据库，然后删除缓存。这种策略的优点是一切以后端数据库为准，可以保证缓存和数据库的一致性。缺点是写操作会让缓存失效，再次读取时需要从数据库中加载。这种策略是我们在开发软件时最常用的，**在使用Memcached或Redis时一般都采用这种方案**。

2、Read/Write Throught策略：应用层读写只需要操作缓存，不需要关心后端数据库。应用层在操作缓存时，缓存层会自动从数据库中加载或写回到数据库中，这种策略的优点是，对于应用层的使用非常友好，只需要操作缓存即可，缺点是需要缓存层支持和后端数据库的联动。

3、Write Back策略：类似于文章所讲的读写缓存模式+异步写回策略。写操作只写缓存，比较简单。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，在加载之前，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库中，再把对应的数据放入到缓存中。这种策略的优点是，写操作飞快（只写缓存），缺点是如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。这种策略经常使用在操作系统Page Cache中，或者应对大量写操作的数据库引擎中。

除了以上提到的缓存和数据库的更新策略之外，还有一个问题就是操作缓存或数据库发生异常时如何处理？例如缓存操作成功，数据库操作失败，或者反过来，还是有可能会产生不一致的情况。

比较简单的解决方案是，根据业务设计好更新缓存和数据库的先后顺序来降低影响，或者给缓存设置较短的有效期来降低不一致的时间。如果需要严格保证缓存和数据库的一致性，即保证两者操作的原子性，这就涉及到分布式事务问题了，常见的解决方案就是我们经常听到的两阶段提交（2PC）、三阶段提交（3PC）、TCC、消息队列等方式来保证了，方案也会比较复杂，一般用在对于一致性要求较高的业务场景中。

## 三.Redis缓存常见问题

### 一致性问题

“一致性”包含了两种情况：

1. 缓存中有数据，那么缓存和数据库中的数据应该是一致的；
2. 缓存中没有数据，那么数据库中的数据应该是最新的。

#### 读写缓存的一致性问题

读写缓存的读写都是要操作缓存；写缓存就会出现一致性问题，读写缓存一般使用写回策略保证缓存和数据库的一致性：

1. 同步直写：同时执行缓存和数据库的写操作；需要使用事务机制，保持两个写操作的原子性才能保证一致性；
2. 异步写回：只写缓存，缓存数据淘汰时和数据库同步数据，缓存宕机会丢失数据，所以一致性问题无法解决。





























### 缓存雪崩